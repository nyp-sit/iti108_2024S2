{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Simple Chatbot with OpenAI API and Gradio"],"metadata":{"id":"akKo1idoWRpT"}},{"cell_type":"markdown","source":["In this practical, we will create a simple chatbot by leveraging the capabilities of a Large Language Model (LLM) and building a user-friendly interface with Gradio. The chatbot will process user inputs, generate responses using LLM, and display them in real time."],"metadata":{"id":"QcpnBQx6WXlh"}},{"cell_type":"markdown","source":["#Load Libraries"],"metadata":{"id":"1MHYxElbqG-K"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"0R3w04uNV__q"},"outputs":[],"source":["!pip install -q gradio\n","!pip install openai\n","!pip install langchain openai tiktoken chromadb python-dotenv langchain_community\n","!pip install U langchain_openai\n","!pip install python-dotenv"]},{"cell_type":"code","source":["import openai\n","openai.__version__"],"metadata":{"id":"C81yctqP0YzY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Download the Openai key\n","\n"],"metadata":{"id":"2anqK8MoODpJ"}},{"cell_type":"code","source":["import gdown\n","url = 'https://drive.google.com/file/d/1U43HPiy3dOLAZNZcw6TNxWmVw4MwM_4F/view?usp=drive_link'\n","output_path = '.env'\n","gdown.download(url, output_path, quiet=False,fuzzy=True)"],"metadata":{"id":"ap_c259oL2rB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Test the ChatGPT with the following questions\n","\n","\n","\n","*   Which is the largest country by area in the world?\n","\n","\n"],"metadata":{"id":"zukXcetUZwil"}},{"cell_type":"code","source":["import os\n","from dotenv import load_dotenv\n","\n","# load .env file to environment\n","load_dotenv()\n","\n","OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n","print(OPENAI_API_KEY)\n","AZURE_ENDPOINT = os.getenv('AZURE_ENDPOINT')\n","print(AZURE_ENDPOINT)\n","DEPLOYMENT_NAME = os.getenv('DEPLOYMENT_NAME')\n","print(DEPLOYMENT_NAME)\n","OPENAI_API_VERSION = os.getenv('OPENAI_API_VERSION')\n","print(OPENAI_API_VERSION)\n"],"metadata":{"id":"uKdnau4fL4n6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from openai import AzureOpenAI\n","\n","AZURE_ENDPOINT = os.getenv('AZURE_ENDPOINT')\n","OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n","DEPLOYMENT_NAME = os.getenv('DEPLOYMENT_NAME')\n","OPENAI_API_VERSION = os.getenv('OPENAI_API_VERSION')\n","\n","\n","from openai import AzureOpenAI\n","\n","\n","client = AzureOpenAI(\n","    api_key=OPENAI_API_KEY,\n","    api_version=OPENAI_API_VERSION,\n","    azure_endpoint=AZURE_ENDPOINT)\n","\n","\n","def get_completion_from_messages(messages, model=DEPLOYMENT_NAME, temperature=0):\n","    response = client.chat.completions.create(\n","        model=model,\n","        messages=messages,\n","        temperature=temperature, # this is the degree of randomness of the model's output\n","    )\n","#     print(str(response.choices[0].message))\n","    return response.choices[0].message.content\n","\n","print(get_completion_from_messages([{'role':'user', 'content':'Which is the largest country by area in the world?'}]))"],"metadata":{"id":"qTx8zuFqMCkd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# LLM Chatbot\n","\n","Create a LLM  Chatbot Class with function to to receive a prompt. The output is the respond from the prompt."],"metadata":{"id":"6YI1YGsRXvV_"}},{"cell_type":"code","source":["from typing import Optional\n","\n","\n","class Chat:\n","\n","    def __init__(self, system: Optional[str] = None):\n","        self.system = system\n","        self.messages = []\n","\n","        if system is not None:\n","            self.messages.append({\n","                \"role\": \"system\",\n","                \"content\": system\n","            })\n","\n","    def prompt(self, content: str) -> str:\n","          self.messages.append({\n","              \"role\": \"user\",\n","              \"content\": content\n","          })\n","          response = get_completion_from_messages(self.messages)\n","\n","\n","          self.messages.append({\n","              \"role\": \"assistant\",\n","              \"content\": response\n","          })\n","          return response"],"metadata":{"id":"og1A3RKpWn8B"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# System prompt\n","\n","Create a system prompt to tune the LLM to be a Chatbot to collect order from customer.\n","\n","In the system prompt instruct the LLM to be OrderBot receive the order from the costumer. In the instruction also provide the menu for the food and the prices."],"metadata":{"id":"bfeux7b61Wfa"}},{"cell_type":"code","source":["\n","system_prompt= f\"\"\"\n","Act as an OrderBot, you work collecting orders in a delivery only fast food restaurant called\n","My Dear Frankfurt. \\\n","First welcome the customer, in a very friedly way, then collects the order. \\\n","You wait to collect the entire order, beverages included \\\n","then summarize it and check for a final \\\n","time if everithing is ok or the customer wants to add anything else. \\\n","Finally you collect the payment.\\\n","Make sure to clarify all options, extras and sizes to uniquely \\\n","identify the item from the menu.\\\n","You respond in a short, very friendly style. \\\n","The menu includes \\\n","burguer  12.95, 10.00, 7.00 \\\n","frankfurt   10.95, 9.25, 6.50 \\\n","sandwich   11.95, 9.75, 6.75 \\\n","fries 4.50, 3.50 \\\n","salad 7.25 \\\n","Toppings: \\\n","extra cheese 2.00, \\\n","mushrooms 1.50 \\\n","martra sausage 3.00 \\\n","canadian bacon 3.50 \\\n","romesco sauce 1.50 \\\n","peppers 1.00 \\\n","Drinks: \\\n","coke 3.00, 2.00, 1.00 \\\n","sprite 3.00, 2.00, 1.00 \\\n","vichy catalan 5.00 \\\n","\"\"\"\n","print(system_prompt)"],"metadata":{"id":"VEeaD1Ln1w6y"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Build Chatbot UI with Gradio\n","\n","Create a respond function with the Chat Class. In the respond function receive the customer query and pass into the Chat object to generate the respond.\n","\n","The Chat object is initialise with the system prompt as part of the context information. It is also save into the chat history. The multi-turn conversation between chatbot and customer will be append to the chat history. This provide some context during the conversation between the chatbot and customer."],"metadata":{"id":"WyRieLm12n6z"}},{"cell_type":"code","source":["import gradio as gr\n","\n","\n","\n","chat = Chat(system= str(system_prompt))\n","\n","\n","def respond(message, chat_history):\n","    bot_message = chat.prompt(content=message)\n","    chat_history.append((message, bot_message))\n","    return \"\", chat_history\n","\n","\n","with gr.Blocks() as demo:\n","    chatbot = gr.Chatbot()\n","    msg = gr.Textbox()\n","    clear = gr.Button(\"Clear\")\n","\n","    msg.submit(respond, [msg, chatbot], [msg, chatbot])\n","    clear.click(lambda: None, None, chatbot, queue=False)\n","\n","demo.launch(debug=True)"],"metadata":{"id":"l6REbRI-X2va"},"execution_count":null,"outputs":[]}]}